<html>
<head>
<title>Heart disease prediction project.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Heart disease prediction project.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>

<span class="s2"># Load the dataset</span>
<span class="s1">df = pd.read_csv(</span><span class="s3">&quot;/Users/sahithipuppala/Desktop/heart data.csv&quot;</span><span class="s1">)</span>

<span class="s2"># Display the first few rows</span>
<span class="s1">df.head()</span>
<span class="s2"># Check for missing values</span>
<span class="s1">print(df.isnull().sum())</span>

<span class="s2"># Basic statistics</span>
<span class="s1">print(df.describe())</span>

<span class="s2"># Check dataset shape</span>
<span class="s1">print(</span><span class="s3">f&quot;Dataset contains </span><span class="s0">{</span><span class="s1">df.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">} </span><span class="s3">rows and </span><span class="s0">{</span><span class="s1">df.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">} </span><span class="s3">columns&quot;</span><span class="s1">)</span>
<span class="s0">import </span><span class="s1">matplotlib.pyplot </span><span class="s0">as </span><span class="s1">plt</span>
<span class="s0">import </span><span class="s1">seaborn </span><span class="s0">as </span><span class="s1">sns</span>

<span class="s2"># Visualize Heart Disease variable</span>
<span class="s1">sns.countplot(x=df[</span><span class="s3">'Heart Disease'</span><span class="s1">])</span>
<span class="s1">plt.title(</span><span class="s3">&quot;Heart Disease Presence (1) vs Absence (0)&quot;</span><span class="s1">)</span>
<span class="s1">plt.show()</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">StandardScaler</span>

<span class="s1">print(df.dtypes)</span>
<span class="s1">df = pd.get_dummies(df</span><span class="s0">, </span><span class="s1">columns=[</span><span class="s3">'Gender'</span><span class="s0">,</span><span class="s3">'Smoking'</span><span class="s0">,</span><span class="s3">'Alcohol Intake'</span><span class="s0">,</span><span class="s3">'Family History'</span><span class="s0">,</span><span class="s3">'Exercise Induced Angina'</span><span class="s0">,</span><span class="s3">'Diabetes'</span><span class="s0">,</span><span class="s3">'Obesity'</span><span class="s0">,</span><span class="s3">'Chest Pain Type'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">drop_first=</span><span class="s0">True</span><span class="s1">)</span>

<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">StandardScaler</span>

<span class="s1">scaler = StandardScaler()</span>
<span class="s1">X_scaled = scaler.fit_transform(df)  </span><span class="s2"># Now, all values should be numeric</span>
<span class="s1">y= df[</span><span class="s3">'Heart Disease'</span><span class="s1">]</span>
<span class="s0">from </span><span class="s1">sklearn.model_selection </span><span class="s0">import </span><span class="s1">train_test_split</span>

<span class="s2"># Split data into 80% train and 20% test</span>
<span class="s1">X_train</span><span class="s0">, </span><span class="s1">X_test</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">y_test = train_test_split(X_scaled</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>

<span class="s0">from </span><span class="s1">sklearn.ensemble </span><span class="s0">import </span><span class="s1">RandomForestClassifier</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">accuracy_score</span><span class="s0">, </span><span class="s1">classification_report</span>

<span class="s2"># Train Random Forest model1</span>
<span class="s1">rf_model = RandomForestClassifier(n_estimators=</span><span class="s4">100</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>
<span class="s1">rf_model.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

<span class="s2"># Predict on test data</span>
<span class="s1">y_pred_rf = rf_model.predict(X_test)</span>

<span class="s2"># Evaluate model</span>
<span class="s1">print(</span><span class="s3">&quot;Random Forest Accuracy:&quot;</span><span class="s0">, </span><span class="s1">accuracy_score(y_test</span><span class="s0">, </span><span class="s1">y_pred_rf))</span>
<span class="s1">print(classification_report(y_test</span><span class="s0">, </span><span class="s1">y_pred_rf))</span>

<span class="s0">from </span><span class="s1">sklearn.svm </span><span class="s0">import </span><span class="s1">SVC</span>

<span class="s2"># Train SVM model2</span>
<span class="s1">svm_model = SVC(kernel=</span><span class="s3">'rbf'</span><span class="s0">, </span><span class="s1">C=</span><span class="s4">1.0</span><span class="s0">, </span><span class="s1">gamma=</span><span class="s3">'scale'</span><span class="s1">)</span>
<span class="s1">svm_model.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

<span class="s2"># Predict on test data</span>
<span class="s1">y_pred_svm = svm_model.predict(X_test)</span>

<span class="s2"># Evaluate model</span>
<span class="s1">print(</span><span class="s3">&quot;SVM Accuracy:&quot;</span><span class="s0">, </span><span class="s1">accuracy_score(y_test</span><span class="s0">, </span><span class="s1">y_pred_svm))</span>
<span class="s1">print(classification_report(y_test</span><span class="s0">, </span><span class="s1">y_pred_svm))</span>

<span class="s0">from </span><span class="s1">sklearn.model_selection </span><span class="s0">import </span><span class="s1">GridSearchCV</span>

<span class="s2"># Define hyperparameter grid for Random Forest</span>
<span class="s1">param_grid = {</span>
    <span class="s3">'n_estimators'</span><span class="s1">: [</span><span class="s4">50</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s4">200</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s3">'max_depth'</span><span class="s1">: [</span><span class="s0">None, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">20</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s3">'min_samples_split'</span><span class="s1">: [</span><span class="s4">2</span><span class="s0">, </span><span class="s4">5</span><span class="s0">, </span><span class="s4">10</span><span class="s1">]</span>
<span class="s1">}</span>

<span class="s1">grid_search = GridSearchCV(RandomForestClassifier()</span><span class="s0">, </span><span class="s1">param_grid</span><span class="s0">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s0">, </span><span class="s1">scoring=</span><span class="s3">'accuracy'</span><span class="s1">)</span>
<span class="s1">grid_search.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

<span class="s2"># Best Parameters</span>
<span class="s1">print(</span><span class="s3">&quot;Best Parameters:&quot;</span><span class="s0">, </span><span class="s1">grid_search.best_params_)</span>
<span class="s1">print(</span><span class="s3">f&quot;Random Forest Accuracy: </span><span class="s0">{</span><span class="s1">accuracy_score(y_test</span><span class="s0">, </span><span class="s1">y_pred_rf)</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">f&quot;SVM Accuracy: </span><span class="s0">{</span><span class="s1">accuracy_score(y_test</span><span class="s0">, </span><span class="s1">y_pred_svm)</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s2"># Get feature importances</span>
<span class="s1">feature_importances = rf_model.feature_importances_</span>
<span class="s1">features = df.drop(columns=[</span><span class="s3">'Heart Disease'</span><span class="s1">]).columns</span>

<span class="s2"># Sort features by importance</span>
<span class="s1">sorted_indices = np.argsort(feature_importances)[::-</span><span class="s4">1</span><span class="s1">]</span>

<span class="s2"># Plot feature importance</span>
<span class="s1">plt.figure(figsize=(</span><span class="s4">10</span><span class="s0">,</span><span class="s4">5</span><span class="s1">))</span>
<span class="s1">print(len(feature_importances))</span>
<span class="s1">print(len(features))</span>
<span class="s1">print(sorted_indices)</span>
<span class="s1">sorted_indices = np.argsort(feature_importances)[::-</span><span class="s4">1</span><span class="s1">][:len(features)]</span>
<span class="s1">print(</span><span class="s3">&quot;Length of feature_importances:&quot;</span><span class="s0">, </span><span class="s1">len(feature_importances))</span>
<span class="s1">print(</span><span class="s3">&quot;Length of features:&quot;</span><span class="s0">, </span><span class="s1">len(features))</span>
<span class="s1">print(</span><span class="s3">&quot;Max index in sorted_indices:&quot;</span><span class="s0">, </span><span class="s1">max(sorted_indices))  </span><span class="s2"># Check if it's too high</span>
<span class="s1">print(</span><span class="s3">&quot;Sorted Indices:&quot;</span><span class="s0">, </span><span class="s1">sorted_indices)</span>
<span class="s2"># First ensure we don't exceed the array bounds</span>
<span class="s1">n_features = len(features)</span>
<span class="s1">valid_indices = [i </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">sorted_indices </span><span class="s0">if </span><span class="s1">i &lt; n_features]</span>

<span class="s2"># Now plot only the valid indices</span>
<span class="s1">sns.barplot(x=feature_importances[valid_indices]</span><span class="s0">,</span>
            <span class="s1">y=np.array(features)[valid_indices])</span>
<span class="s1">plt.xlabel(</span><span class="s3">&quot;Feature Importance&quot;</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s3">&quot;Features&quot;</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">&quot;Random Forest Feature Importance&quot;</span><span class="s1">)</span>
<span class="s1">plt.show()</span></pre>
</body>
</html>